\chapter{Subspace Identification Methods}
Subspace identification methods (SIM) provide an approach to identifing LTI systems in their state space form using input-output data. SIMs provide an attractive alternative to Prediction Error Methods (PEM) because of their ability to identify MIMO systems and their non-iterative solution nature, making them suitable for working with large data sets. In general, the subspace identification problem is: given a set of input and output data, estimate the system matrices ($A$, $B$, $C$, $D$) up to within a similarity transform. 

Extensive work in both the theory and application of SIMs in the last 20 years has resulted in the development of a number of popular algorithms, including the canonical variate analysis (CVA) method proposed by Larimore \cite{larimore1990canonical}, the multi-variable output-error state space (MOESP) method proposed by Verhaegen \cite{verhaegen1992subspace}, and the numerical algorithms for subspace state space system identification (N4SID) proposed by Van Overschee and De Moor \cite{van1994n4sid}. A unifying theorem proposed by Van Overschee and De Moor \cite{van1995unifying} links these algorithms and provides a generalized approach to the subspace identification problem.  

As described in Van Overschee and De Moor's unifying theorem, all SIMs follow the same general two step procedure. First, estimate the subspace spanned by the columns of the extended observability matrix ($\Gamma_k$) from input-output data $u_k$, $y_k$. The dimension of $\Gamma_k$ determines the order $n$ of the estimated system. The system order is determined and $\Gamma_k$ reduced accordingly. Second, the system matrices are determined, either directly from the extended observability matrix or from the realized state sequence $X_k$.

Until recently, SIMs were unable to identify systems operating in the presence of feedback control(i.e. closed-loop). In the open-loop case, input data is uncorrelated with past noise. When a system is operating in closed-loop, the presence of feedback control causes the input to be correlated with past noise as the controller attempts to eliminate system disturbances \cite{qin2006overview}. The result is a system that is biased when identified using traditional SIMs. Several new approaches to identifying closed-loop systems by decoupling inputs from past noise have been proposed, most notably the innovation estimation method (IEM) proposed by Qin and Ljung \cite{qin2003closed} and the whitening filter approach (WFA) proposed by Chiuso and Picci \cite{chiuso2005consistency}.


\section{Open-Loop Subspace Identification}
When a system is operating in open-loop (i.e. no feedback), the input data is assumed to be independent of past noise. In this case, the traditional SIMs (MOESP, N4SID, CVA) can be used without modification. 

\subsection{Extended State Space Model}
Recalling the combined deterministic-stochastic LTI system is given in its innovation form as
\begin{subequations}\label{eq:3_innovation}
\begin{equation}x(k+1) = Ax(k) + Bu(k) + Ke(k)\end{equation}
\begin{equation}y(k) = Cx(k) + Du(k) + e(k)\end{equation}
\end{subequations}
Based on the state space model in (\ref{eq:3_innovation}), an extended state space model can be formulated as
\begin{equation}\label{eq:3_extended_state_space}
Y_f = \Gamma_f X_k + H_f U_f + G_f E_f
\end{equation}
where the subscript $f$ denotes the future horizon. The extended observability matrix is
\begin{equation}\label{eq:3_extended_observability}
\Gamma_f = \begin{bmatrix}C\\ CA\\ \vdots\\ CA^{f-1}\end{bmatrix}
\end{equation}
and $H_f$ and $G_f$ are Toeplitz matrices of the Markov parameters of the deterministic and stochastic subsystems, respectively
\begin{subequations}\label{eq:3_toeplitz}
\begin{equation}
H_f = \begin{bmatrix}
D & 0 & 0 & \cdots & 0\\
CB & D & 0 & \cdots & 0\\
CAB & CB & D & \cdots & 0\\
\vdots & \vdots  & \vdots & \ddots & \vdots\\
CA^{f-2}B & CA^{f-3}B & CA^{f-4}B & \cdots & D
\end{bmatrix}
\end{equation}
\begin{equation}
G_f = \begin{bmatrix}
I & 0 & 0 & \cdots & 0\\
CK & I & 0 & \cdots & 0\\
CAK & CK & I & \cdots & 0\\
\vdots & \vdots  & \vdots & \ddots & \vdots\\
CA^{f-2}K & CA^{f-3}K & CA^{f-4}K & \cdots & I
\end{bmatrix}
\end{equation}
\end{subequations}
Equation (\ref{eq:3_extended_state_space}) relates matrices of input-output data to matrices of the system matrices. We will leverage this structure to identify the unknown system matrices from known input-output data. In particular, we will estimate the column space of the extended observability matrix. Knowledge of this subspace is sufficient to then estimate the unknown system matrices. 

\subsection{Input-Output Data}
The structure of (\ref{eq:3_extended_state_space}) requires the input, output, and noise sequences be represented in block Hankel form. For the input sequence
\begin{equation}\label{eq:3_input}
U_f = \begin{bmatrix}
u(k) & u(k+1) & \cdots & u(k+N-1)\\
u(k+1) & u(k+2) & \cdots & u(k+N)\\
\vdots & \vdots & \ddots & \vdots\\
u(k+f-1) & u(k+f) & \cdots & u(k+f+N-2)
\end{bmatrix}
\end{equation}
We similarly arrange the output data $Y_f$ and noise $E_f$ according to the same Hankel form.

!!!!! Need to discuss past and future splitting !!!!!

\begin{equation*}
Z_p = \begin{bmatrix} U_p\\ Y_p\end{bmatrix}
\end{equation*}

\subsection{Estimation of the Extended Observability Matrix}
Estimate $\Gamma_f$ from (\ref{eq:3_extended_state_space}) via MOESP: linear regression followed by an SVD to estimate EOM.

First, eliminate $U_f$ by post-multiplying (\ref{eq:3_extended_state_space}) by $\Pi_{U_f}^\perp$ (eliminate the influence of the input) giving
\begin{equation}
Y_f\Pi_{U_f}^\perp = \Gamma_f X_k\Pi_{U_f}^\perp + G_f E_f\Pi_{U_f}^\perp
\end{equation}
Recalling $E_f$ is uncorrelated with $U_f$, 
\begin{equation}
Y_f\Pi_{U_f}^\perp = \Gamma_f X_k\Pi_{U_f}^\perp + G_f E_f
\end{equation}
Next we eliminate the influence of the noise term $E_f$. From Kalman filter theory, $E_f$ is uncorrelated with $Z_p$ (cite Qin overview paper on this one):
\begin{equation*}
\lim_{N\rightarrow\infty}\frac{1}{N}E_fZ_p^T =0
\end{equation*}
Thus multiplying (3.7) on the right by $Z_p$ gives
\begin{equation}
Y_f\Pi_{U_f}^\perp Z_p = \Gamma_f X_k\Pi_{U_f}^\perp Z_p
\end{equation}


\subsection{Determination of the System Matrices}




\section{Closed-Loop Subspace Identification}

Under open-loop conditions, $E_f$ is uncorrelated with $U_f$. That is,
\begin{equation*}
\lim_{N\rightarrow\infty}\frac{1}{N}E_fU_f^T =0
\end{equation*}
or 
\begin{equation*}
E_f \Pi_{U_f}^\perp = E_f(I-U_f^T(U_fU_f^T)^{-1}U_f) = E_f
\end{equation*}

\subsection{Identifying Systems Operating Under Feedback Control}

\subsection{Innovation Estimation Method}

\subsection{Whitening Filter}
